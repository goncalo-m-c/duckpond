"""initial_schema

Revision ID: a12ae57a3abf
Revises: 
Create Date: 2025-10-26 19:33:22.220551

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = 'a12ae57a3abf'
down_revision: Union[str, Sequence[str], None] = None
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('tenants',
    sa.Column('tenant_id', sa.String(length=64), nullable=False, comment='Unique tenant identifier with format tenant-{slug}'),
    sa.Column('name', sa.String(length=255), nullable=False, comment='Unique tenant name'),
    sa.Column('api_key_hash', sa.String(length=255), nullable=False, comment='Hashed API key for tenant authentication'),
    sa.Column('ducklake_catalog_url', sa.String(length=512), nullable=False, comment='URL for DuckLake catalog REST API'),
    sa.Column('storage_backend', sa.String(length=16), nullable=False, comment='Storage backend type (s3, azure, gcs, local)'),
    sa.Column('storage_config', sa.JSON(), nullable=True, comment='JSON configuration for storage backend'),
    sa.Column('max_storage_gb', sa.Integer(), nullable=False, comment='Maximum storage quota in gigabytes'),
    sa.Column('max_query_memory_gb', sa.Integer(), nullable=False, comment='Maximum query memory in gigabytes'),
    sa.Column('max_concurrent_queries', sa.Integer(), nullable=False, comment='Maximum number of concurrent queries'),
    sa.Column('created_at', sa.DateTime(), nullable=False, comment='Timestamp when tenant was created'),
    sa.Column('updated_at', sa.DateTime(), nullable=False, comment='Timestamp when tenant was last updated'),
    sa.PrimaryKeyConstraint('tenant_id'),
    sa.UniqueConstraint('name')
    )
    op.create_index('idx_tenants_name', 'tenants', ['name'], unique=False)
    op.create_index('idx_tenants_storage_backend', 'tenants', ['storage_backend'], unique=False)
    op.create_table('api_keys',
    sa.Column('key_id', sa.String(length=64), nullable=False, comment='Unique API key identifier'),
    sa.Column('tenant_id', sa.String(length=64), nullable=False, comment='Tenant this API key belongs to'),
    sa.Column('key_hash', sa.String(length=255), nullable=False, comment='Hashed API key for authentication'),
    sa.Column('description', sa.String(length=512), nullable=True, comment='Optional description of API key purpose'),
    sa.Column('created_at', sa.DateTime(), nullable=False, comment='Timestamp when API key was created'),
    sa.Column('last_used', sa.DateTime(), nullable=True, comment='Timestamp when API key was last used'),
    sa.Column('expires_at', sa.DateTime(), nullable=True, comment='Timestamp when API key expires'),
    sa.ForeignKeyConstraint(['tenant_id'], ['tenants.tenant_id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('key_id'),
    sa.UniqueConstraint('key_hash')
    )
    op.create_index('idx_api_keys_expires', 'api_keys', ['expires_at'], unique=False)
    op.create_index('idx_api_keys_hash', 'api_keys', ['key_hash'], unique=False)
    op.create_index('idx_api_keys_tenant', 'api_keys', ['tenant_id'], unique=False)
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_index('idx_api_keys_tenant', table_name='api_keys')
    op.drop_index('idx_api_keys_hash', table_name='api_keys')
    op.drop_index('idx_api_keys_expires', table_name='api_keys')
    op.drop_table('api_keys')
    op.drop_index('idx_tenants_storage_backend', table_name='tenants')
    op.drop_index('idx_tenants_name', table_name='tenants')
    op.drop_table('tenants')
    # ### end Alembic commands ###
